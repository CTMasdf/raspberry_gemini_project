import os
import subprocess
import time
import json
import serial
import speech_recognition as sr
from gtts import gTTS
from dotenv import load_dotenv
import google.generativeai as genai

# ------------------- í™˜ê²½ ë³€ìˆ˜ & Gemini API -------------------
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-1.5-flash")

# ------------------- ê²½ë¡œ ì„¤ì • -------------------
IMAGE_PATH = "/home/aibot/chatbot_project/capture.jpg"
HISTORY_FILE = "conversation_history.json"

# ------------------- ì•„ë‘ì´ë…¸ ì‹œë¦¬ì–¼ -------------------
COMMAND_KEYWORDS = [
    'M_Sunny', 'M_partly_cloudy', 'M_cloudy', 'M_rainy', 'M_sleet', 'M_snowy',
    'M_stop', 'M_forward', 'M_backward', 'M_turn_left', 'M_turn_right',
    'M_spin_left', 'M_spin_right', 'M_home'
]

try:
    arduino = serial.Serial('/dev/ttyACM0', 9600, timeout=1)
    print("âœ… ì•„ë‘ì´ë…¸ ì—°ê²° ì„±ê³µ")
except Exception as e:
    print(f"âŒ ì•„ë‘ì´ë…¸ ì—°ê²° ì‹¤íŒ¨: {e}")
    arduino = None
time.sleep(2)

# ------------------- ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ -------------------
def load_conversation_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_conversation_history():
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(conversation_history, f, ensure_ascii=False, indent=2)

conversation_history = load_conversation_history()

# ------------------- STT -------------------
def recognize_speech(prompt=None):
    r = sr.Recognizer()
    with sr.Microphone() as source:
        if prompt:
            print(prompt)
        audio = r.listen(source)
        try:
            text = r.recognize_google(audio, language="ko-KR")
            print("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", text)
            return text
        except:
            print("âš ï¸ ìŒì„± ì¸ì‹ ì‹¤íŒ¨")
            return ""

# ------------------- TTS -------------------
def speak_text(text):
    print("ğŸ¤– Gemini:", text)
    tts = gTTS(text=text, lang="ko")
    tts.save("response.mp3")
    os.system("mpg321 -q response.mp3")

# ------------------- ì•„ë‘ì´ë…¸ -------------------
def extract_command(text):
    text_lower = text.lower()
    for keyword in COMMAND_KEYWORDS:
        if keyword.lower() in text_lower:
            return keyword
    return None

def send_to_arduino(command):
    if command and arduino:
        try:
            arduino.write((command + '\n').encode('utf-8'))
            print("ì•„ë‘ì´ë…¸ë¡œ ì „ì†¡:", command)
        except Exception as e:
            print("âš ï¸ ì•„ë‘ì´ë…¸ ì „ì†¡ ì˜¤ë¥˜:", e)

# ------------------- Gemini API -------------------
def generate_response(prompt):
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Gemini ì˜¤ë¥˜: {e}"

def build_prompt():
    prompt = ""
    for msg in conversation_history:
        role = "User" if msg["role"] == "user" else "Chatbot"
        prompt += f"{role}: {msg['parts']}\n"
    return prompt

# ------------------- ì‚¬ì§„ ì´¬ì˜ -------------------
def take_picture():
    subprocess.run(["rpicam-still", "-o", IMAGE_PATH])
    print("ğŸ“· ì‚¬ì§„ ì´¬ì˜ ì™„ë£Œ:", IMAGE_PATH)

def ask_gemini_about_image():
    if not os.path.exists(IMAGE_PATH):
        return "ì‚¬ì§„ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    with open(IMAGE_PATH, "rb") as f:
        image_data = f.read()
    response = model.generate_content(
        ["ë°©ê¸ˆ ì°ì€ ì‚¬ì§„ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜.", {"mime_type": "image/jpeg", "data": image_data}]
    )
    return response.text

# ------------------- ëª…ë ¹ì–´ ì²˜ë¦¬ -------------------
def handle_command(user_text):
    if "ì‚¬ì§„" in user_text and ("ì°" in user_text or "ì´¬ì˜" in user_text):
        take_picture()
        answer = ask_gemini_about_image()
    else:
        conversation_history.append({"role": "user", "parts": user_text})
        prompt = build_prompt()
        answer = generate_response(prompt)
        conversation_history.append({"role": "model", "parts": answer})
        save_conversation_history()

    # ì•„ë‘ì´ë…¸ ëª…ë ¹ì–´ ì¶”ì¶œ
    command = extract_command(answer)
    send_to_arduino(command)

    speak_text(answer)

# ------------------- ì±—ë´‡ ë©”ì¸ ë£¨í”„ -------------------
def chat_bot():
    print("ğŸ™ï¸ ì•„ì´ë´‡ ìŒì„± ì±—ë´‡ ì‹œì‘. 'ë§ˆë¦°'ì´ë¼ê³  ë§í•˜ë©´ ì§ˆë¬¸ì„ ë°›ì„ê²Œìš”.")
    while True:
        trigger = recognize_speech("'ë§ˆë¦°'ë¼ê³  ë§í•´ì£¼ì„¸ìš”")
        if "ë§ˆë¦°" in trigger:
            speak_text("ì§ˆë¬¸í•˜ì„¸ìš”")
            question = recognize_speech("ì§ˆë¬¸ì„ ë§í•´ì£¼ì„¸ìš”")
            if not question:
                continue

            if "ì¢…ë£Œ" in question or "ê·¸ë§Œ" in question:
                speak_text("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê³„ì„¸ìš”!")
                break

            handle_command(question)

# ------------------- ì‹¤í–‰ -------------------
if __name__ == "__main__":
    chat_bot()
